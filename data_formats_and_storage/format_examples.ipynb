{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0822fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import fastavro\n",
    "from io import BytesIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4136f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "data = {\n",
    "    'name': ['John', 'Alice', 'Bob'],\n",
    "    'age': [30, 25, 35],\n",
    "    'city': ['New York', 'San Francisco', 'Chicago']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdafa25a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2faf28",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created: output/sample.csv\n",
      "\n",
      "Read CSV data:\n",
      "    name  age           city\n",
      "0   John   30       New York\n",
      "1  Alice   25  San Francisco\n",
      "2    Bob   35        Chicago\n"
     ]
    }
   ],
   "source": [
    "# 1. CSV Example\n",
    "def csv_example():\n",
    "    df = pd.DataFrame(data)\n",
    "    csv_file = f'{output_dir}/sample.csv'\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"CSV file created: {csv_file}\")\n",
    "    \n",
    "    # Read back CSV\n",
    "    df_read = pd.read_csv(csv_file)\n",
    "    print(\"\\nRead CSV data:\")\n",
    "    print(df_read)\n",
    "csv_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5fe766e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JSON file created: output/sample.json\n",
      "\n",
      "Read JSON data:\n",
      "{'name': ['John', 'Alice', 'Bob'], 'age': [30, 25, 35], 'city': ['New York', 'San Francisco', 'Chicago']}\n"
     ]
    }
   ],
   "source": [
    "# 2. JSON Example\n",
    "def json_example():\n",
    "    json_file = f'{output_dir}/sample.json'\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    print(f\"\\nJSON file created: {json_file}\")\n",
    "    \n",
    "    # Read back JSON\n",
    "    with open(json_file, 'r') as f:\n",
    "        data_read = json.load(f)\n",
    "    print(\"\\nRead JSON data:\")\n",
    "    print(data_read)\n",
    "json_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b56bc5d1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parquet file created: output/sample.parquet\n",
      "\n",
      "Read Parquet data:\n",
      "    name  age           city\n",
      "0   John   30       New York\n",
      "1  Alice   25  San Francisco\n",
      "2    Bob   35        Chicago\n"
     ]
    }
   ],
   "source": [
    "# 3. Parquet Example\n",
    "def parquet_example():\n",
    "    df = pd.DataFrame(data)\n",
    "    parquet_file = f'{output_dir}/sample.parquet'\n",
    "    df.to_parquet(parquet_file)\n",
    "    print(f\"\\nParquet file created: {parquet_file}\")\n",
    "    \n",
    "    # Read back Parquet\n",
    "    df_read = pd.read_parquet(parquet_file)\n",
    "    print(\"\\nRead Parquet data:\")\n",
    "    print(df_read)\n",
    "parquet_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca485a8b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avro file created: output/sample.avro\n",
      "\n",
      "Read Avro data:\n",
      "{'name': 'John', 'age': 30, 'city': 'New York'}\n",
      "{'name': 'Alice', 'age': 25, 'city': 'San Francisco'}\n",
      "{'name': 'Bob', 'age': 35, 'city': 'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "# 4. Avro Example\n",
    "def avro_example():\n",
    "    schema = {\n",
    "        'type': 'record',\n",
    "        'name': 'User',\n",
    "        'fields': [\n",
    "            {'name': 'name', 'type': 'string'},\n",
    "            {'name': 'age', 'type': 'int'},\n",
    "            {'name': 'city', 'type': 'string'}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Prepare records\n",
    "    records = []\n",
    "    for i in range(len(data['name'])):\n",
    "        records.append({\n",
    "            'name': data['name'][i],\n",
    "            'age': data['age'][i],\n",
    "            'city': data['city'][i]\n",
    "        })\n",
    "    \n",
    "    avro_file = f'{output_dir}/sample.avro'\n",
    "    with open(avro_file, 'wb') as f:\n",
    "        fastavro.writer(f, schema, records)\n",
    "    print(f\"\\nAvro file created: {avro_file}\")\n",
    "    \n",
    "    # Read back Avro\n",
    "    with open(avro_file, 'rb') as f:\n",
    "        reader = fastavro.reader(f)\n",
    "        print(\"\\nRead Avro data:\")\n",
    "        for record in reader:\n",
    "            print(record)\n",
    "avro_example()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
